{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kZ_ZUE2BrFyF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=2, out_channels=1, timesteps=1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_timesteps = timesteps\n",
        "\n",
        "        def conv_block(in_ch, out_ch):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(1, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 28 * 28)\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc1 = conv_block(2, 64)\n",
        "        self.enc2 = conv_block(64, 128)\n",
        "        self.enc3 = conv_block(128, 256)\n",
        "\n",
        "        self.bottleneck = conv_block(256, 512)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2, output_padding=1)\n",
        "        self.dec3 = conv_block(512, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = conv_block(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = conv_block(128, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        t_embed = self.time_embed(t.float().view(-1, 1) / 1000.0).view(-1, 1, 28, 28)\n",
        "        x = torch.cat([x, t_embed], dim=1)\n",
        "\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool(e1))\n",
        "        e3 = self.enc3(self.pool(e2))\n",
        "\n",
        "        b = self.bottleneck(self.pool(e3))\n",
        "\n",
        "        d3 = self.dec3(torch.cat([self.up3(b), e3], dim=1))\n",
        "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
        "\n",
        "        return self.final(d1)\n"
      ],
      "metadata": {
        "id": "_oaNfjAurP01"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(in_channels=2, out_channels=1, timesteps=1000)\n",
        "x = torch.randn(1, 1, 28, 28)\n",
        "y = model(x, torch.tensor([2]))\n",
        "print(y.shape)  # should print: torch.Size([1, 1, 28, 28])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU672OIZ1yxI",
        "outputId": "9d6c0941-71f0-484d-c905-0f56d501548c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0.0001, 0.999)"
      ],
      "metadata": {
        "id": "0ABdNSfctF8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DDPM:\n",
        "    def __init__(self, model, timesteps=1000):\n",
        "        self.model = model\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.timesteps = timesteps\n",
        "        self.betas = cosine_beta_schedule(timesteps).to(self.device)\n",
        "        self.alphas = 1. - self.betas\n",
        "        self.alpha_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "        # Precompute constants\n",
        "        self.sqrt_alpha_hat = torch.sqrt(self.alpha_hat).to(self.device)\n",
        "        self.sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat).to(self.device)\n",
        "\n",
        "    def add_noise(self, x0, t, noise):\n",
        "        return (\n",
        "            self.sqrt_alpha_hat[t][:, None, None, None] * x0 +\n",
        "            self.sqrt_one_minus_alpha_hat[t][:, None, None, None] * noise\n",
        "        )\n",
        "\n",
        "    def train(self, dataloader, optimizer, epochs=10, use_ema=True):\n",
        "        ema_model = UNet().to(self.device)\n",
        "        ema_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "        def update_ema(ema, model, decay=0.9999):\n",
        "            for ema_param, param in zip(ema.parameters(), model.parameters()):\n",
        "                ema_param.data.mul_(decay).add_(param.data, alpha=1 - decay)\n",
        "\n",
        "        self.model.train()\n",
        "        for epoch in range(epochs):\n",
        "            loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "            for x, _ in loop:\n",
        "                x = x.to(self.device)\n",
        "                t = torch.randint(0, self.timesteps, (x.size(0),), device=self.device)\n",
        "                noise = torch.randn_like(x)\n",
        "                x_noisy = self.add_noise(x, t, noise)\n",
        "\n",
        "                predicted = self.model(x_noisy, t)\n",
        "                loss = F.mse_loss(predicted, noise)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                if use_ema:\n",
        "                    update_ema(ema_model, self.model)\n",
        "\n",
        "                loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        if use_ema:\n",
        "            self.model.load_state_dict(ema_model.state_dict())\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, shape, steps=None):\n",
        "        steps = steps or self.timesteps\n",
        "        x = torch.randn(shape).to(self.device)\n",
        "        for t in reversed(range(steps)):\n",
        "            t_batch = torch.full((shape[0],), t, device=self.device, dtype=torch.long)\n",
        "            beta = self.betas[t]\n",
        "            alpha = self.alphas[t]\n",
        "            alpha_hat = self.alpha_hat[t]\n",
        "\n",
        "            pred_noise = self.model(x, torch.tensor([t]).to(self.device))\n",
        "            x = (1 / alpha.sqrt()) * (x - (1 - alpha) / (1 - alpha_hat).sqrt() * pred_noise)\n",
        "            if t > 0:\n",
        "                noise = torch.randn_like(x)\n",
        "                x += beta.sqrt() * noise\n",
        "\n",
        "        return torch.clamp((x + 1) / 2, 0, 1)"
      ],
      "metadata": {
        "id": "belPnU4ttGHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x * 2 - 1)  # [-1, 1]\n",
        "])\n",
        "dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True)"
      ],
      "metadata": {
        "id": "9EcYQX_bv5pP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab48b55-13ea-44b7-bd8e-eb3ee2184dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 58.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.64MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.6MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.06MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet()\n",
        "ddpm = DDPM(model, timesteps=1000)\n",
        "optimizer = torch.optim.Adam(ddpm.model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "BxhZDzt7tv9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm.train(dataloader, optimizer, epochs=10)\n",
        "torch.save(ddpm.model.state_dict(), \"unet.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "kvo8k1Rsd2Xo",
        "outputId": "f34202dd-f8f9-43b6-825a-41971c6ad8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 59/59 [00:41<00:00,  1.42it/s, loss=0.487]\n",
            "Epoch 2: 100%|██████████| 59/59 [00:39<00:00,  1.48it/s, loss=0.243]\n",
            "Epoch 3: 100%|██████████| 59/59 [00:40<00:00,  1.44it/s, loss=0.204]\n",
            "Epoch 4: 100%|██████████| 59/59 [00:40<00:00,  1.46it/s, loss=0.183]\n",
            "Epoch 5: 100%|██████████| 59/59 [00:40<00:00,  1.46it/s, loss=0.171]\n",
            "Epoch 6:  27%|██▋       | 16/59 [00:11<00:31,  1.37it/s, loss=0.155]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-5510616acb86>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unet.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-59c6e6821bc4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, optimizer, epochs, use_ema)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mupdate_ema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mema_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_ema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(ddpm.model.state_dict(), \"unet.pth\")"
      ],
      "metadata": {
        "id": "LjHruv0_b2xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_load = UNet()\n",
        "model_load.load_state_dict(torch.load(\"/content/drive/MyDrive/Colabs/unet.pth\"))\n",
        "model_load.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj7Y0sqdcBre",
        "outputId": "45f47863-8157-4ce1-9b48-ba87b29b1b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (time_embed): Sequential(\n",
              "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=784, bias=True)\n",
              "  )\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (enc1): Sequential(\n",
              "    (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (enc2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (enc3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (bottleneck): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (up3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), output_padding=(1, 1))\n",
              "  (dec3): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (up2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (dec2): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (up1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (dec1): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (final): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm_eval = DDPM(model_load, timesteps=1000)"
      ],
      "metadata": {
        "id": "zPHmH9zuciMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = ddpm.sample((1, 1, 28, 28))\n",
        "grid = utils.make_grid(samples, nrow=4)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "nOsUXc7ktwCn",
        "outputId": "273d6b85-0c9c-4f73-919c-d4fc24860558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Loader from CSV\n",
        "# -------------------------\n",
        "class MNISTFromCSV(Dataset):\n",
        "    def __init__(self, csv_path):\n",
        "        df = pd.read_csv(csv_path, header=None)\n",
        "        print(df.iloc[1:, 0].values)\n",
        "        self.labels = torch.tensor(df.iloc[1:, 0].values)\n",
        "        self.images = torch.tensor(df.iloc[1:, 1:].values.astype(\"float32\") / 255.0)\n",
        "        self.images = self.images.view(-1, 1, 28, 28)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "# -------------------------\n",
        "# Simple U-Net\n",
        "# -------------------------\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        def conv_block(in_ch, out_ch):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(1, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 28 * 28)\n",
        "        )\n",
        "\n",
        "        self.enc1 = conv_block(2, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = conv_block(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = conv_block(128, 256)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = conv_block(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = conv_block(128, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        t_embed = self.time_embed(t.float().view(-1, 1) / 1000.0).view(-1, 1, 28, 28)\n",
        "        x = torch.cat([x, t_embed], dim=1)\n",
        "\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        b = self.bottleneck(self.pool2(e2))\n",
        "\n",
        "        d2 = self.dec2(torch.cat([self.up2(b), e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
        "\n",
        "        return self.final(d1)\n",
        "\n",
        "# -------------------------\n",
        "# DDPM Logic\n",
        "# -------------------------\n",
        "class DDPM:\n",
        "    def __init__(self, timesteps=1000):\n",
        "        self.timesteps = timesteps\n",
        "        self.betas = torch.linspace(1e-4, 0.02, timesteps)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alpha_hats = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def add_noise(self, x0, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        alpha_hat = self.alpha_hats[t].view(-1, 1, 1, 1)\n",
        "        return torch.sqrt(alpha_hat) * x0 + torch.sqrt(1 - alpha_hat) * noise, noise\n",
        "\n",
        "    def sample(self, model, n_samples=1, device='cpu'):\n",
        "        x = torch.randn(n_samples, 1, 28, 28).to(device)\n",
        "        for t in reversed(range(self.timesteps)):\n",
        "            time_tensor = torch.full((n_samples,), t, dtype=torch.long, device=device)\n",
        "            with torch.no_grad():\n",
        "                eps_theta = model(x, time_tensor)\n",
        "            beta = self.betas[t]\n",
        "            alpha = self.alphas[t]\n",
        "            alpha_hat = self.alpha_hats[t]\n",
        "            noise = torch.randn_like(x) if t > 0 else 0\n",
        "            x = (1 / torch.sqrt(alpha)) * (x - beta / torch.sqrt(1 - alpha_hat) * eps_theta) + torch.sqrt(beta) * noise\n",
        "        return x\n",
        "\n",
        "# -------------------------\n",
        "# Image Saving\n",
        "# -------------------------\n",
        "def save_grid(samples, filename):\n",
        "    samples = samples.cpu().squeeze(1)\n",
        "    fig, axs = plt.subplots(4, 4, figsize=(4, 4))\n",
        "    for i, ax in enumerate(axs.flat):\n",
        "        ax.imshow(samples[i], cmap=\"gray\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "\n",
        "# -------------------------\n",
        "# Training Loop\n",
        "# -------------------------\n",
        "def train(csv_path, epochs=50, batch_size=128, sample_every=10, device='cpu'):\n",
        "    dataset = MNISTFromCSV(csv_path)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = UNet().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    ddpm = DDPM()\n",
        "\n",
        "    os.makedirs(\"samples\", exist_ok=True)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        for x0, _ in dataloader:\n",
        "            x0 = x0.to(device)\n",
        "            t = torch.randint(0, ddpm.timesteps, (x0.size(0),), device=device)\n",
        "            xt, noise = ddpm.add_noise(x0, t)\n",
        "            noise_pred = model(xt, t)\n",
        "\n",
        "            loss = F.mse_loss(noise_pred, noise)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "        if epoch % sample_every == 0:\n",
        "            model.eval()\n",
        "            samples = ddpm.sample(model, n_samples=16, device=device)\n",
        "            save_grid(samples, f\"samples/sample_{epoch:03d}.png\")\n",
        "\n",
        "# -------------------------\n",
        "# CLI Entry Point\n",
        "# -------------------------\n",
        "train('/content/drive/MyDrive/Colabs/mnist_complete.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "R6xr3rlL5A-2",
        "outputId": "7b5d51f3-ebe2-4a7a-aa26-27739dcf2244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['5' '0' '4' ... 4 5 6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-f86b708676f1>:14: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_path, header=None)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f86b708676f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;31m# CLI Entry Point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m# -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colabs/mnist_complete.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-f86b708676f1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(csv_path, epochs, batch_size, sample_every, device)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNISTFromCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-f86b708676f1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3U8q4-Yd8-zq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}